{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 422 - Big Data - Bonus Assignment - Amazon review Sentiment Analysis\n",
    "\n",
    "Team Nugget - Crystal, Daria, Mei, Pallavi, Sarah\n",
    "\n",
    "March 10th, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://jmcauley.ucsd.edu/data/amazon/\n",
    "* Amazon Reviews and Ratings Data\n",
    "* Includes metadata for things like ‘related products’\n",
    "* Use the ‘small’ 5-core books dataset\n",
    "* Use the free text of the reviews to do a sentiment analysis\n",
    "* Group sentiment into Negative, Neutral, Positive\n",
    "* Understand characteristics of the hardware you’re running this on\n",
    "* Time execution and measure memory usage of both training phase and model usage phase\n",
    "* Estimate (in words and numbers, show work) time (and resources) required to handle full book dataset with daily updates\n",
    "* Estimate (in words and numbers, show work) time and resources required to use daily-built models to classify sentiment of a new review within 100 milliseconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"System-Config.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import resource\n",
    "from memory_profiler import profile\n",
    "from time import time\n",
    "%load_ext memory_profiler\n",
    "\n",
    "import re, nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer        \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100000 entries, 0 to 99999\n",
      "Data columns (total 9 columns):\n",
      "asin              100000 non-null object\n",
      "helpful           100000 non-null object\n",
      "overall           100000 non-null int64\n",
      "reviewText        100000 non-null object\n",
      "reviewTime        100000 non-null object\n",
      "reviewerID        100000 non-null object\n",
      "reviewerName      99951 non-null object\n",
      "summary           100000 non-null object\n",
      "unixReviewTime    100000 non-null int64\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#data = pd.read_json(\"review_Books_5.json\", lines = True)\n",
    "data = pd.read_json(\"sample_100k.json\", lines = True) # sampled 100k rows from 5-core book using terminal\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000100039X</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>Spiritually and mentally inspiring! A book tha...</td>\n",
       "      <td>12 16, 2012</td>\n",
       "      <td>A10000012B7CGYKOMPQ4L</td>\n",
       "      <td>Adam</td>\n",
       "      <td>Wonderful!</td>\n",
       "      <td>1355616000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000100039X</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>5</td>\n",
       "      <td>This is one my must have books. It is a master...</td>\n",
       "      <td>12 11, 2003</td>\n",
       "      <td>A2S166WSCFIFP5</td>\n",
       "      <td>adead_poet@hotmail.com \"adead_poet@hotmail.com\"</td>\n",
       "      <td>close to god</td>\n",
       "      <td>1071100800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000100039X</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>This book provides a reflection that you can a...</td>\n",
       "      <td>01 18, 2014</td>\n",
       "      <td>A1BM81XB4QHOA3</td>\n",
       "      <td>Ahoro Blethends \"Seriously\"</td>\n",
       "      <td>Must Read for Life Afficianados</td>\n",
       "      <td>1390003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000100039X</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>I first read THE PROPHET in college back in th...</td>\n",
       "      <td>09 27, 2011</td>\n",
       "      <td>A1MOSTXNIO5MPJ</td>\n",
       "      <td>Alan Krug</td>\n",
       "      <td>Timeless for every good and bad time in your l...</td>\n",
       "      <td>1317081600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000100039X</td>\n",
       "      <td>[7, 9]</td>\n",
       "      <td>5</td>\n",
       "      <td>A timeless classic.  It is a very demanding an...</td>\n",
       "      <td>10 7, 2002</td>\n",
       "      <td>A2XQ5LZHTD4AFT</td>\n",
       "      <td>Alaturka</td>\n",
       "      <td>A Modern Rumi</td>\n",
       "      <td>1033948800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin helpful  overall  \\\n",
       "0  000100039X  [0, 0]        5   \n",
       "1  000100039X  [0, 2]        5   \n",
       "2  000100039X  [0, 0]        5   \n",
       "3  000100039X  [0, 0]        5   \n",
       "4  000100039X  [7, 9]        5   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  Spiritually and mentally inspiring! A book tha...  12 16, 2012   \n",
       "1  This is one my must have books. It is a master...  12 11, 2003   \n",
       "2  This book provides a reflection that you can a...  01 18, 2014   \n",
       "3  I first read THE PROPHET in college back in th...  09 27, 2011   \n",
       "4  A timeless classic.  It is a very demanding an...   10 7, 2002   \n",
       "\n",
       "              reviewerID                                     reviewerName  \\\n",
       "0  A10000012B7CGYKOMPQ4L                                             Adam   \n",
       "1         A2S166WSCFIFP5  adead_poet@hotmail.com \"adead_poet@hotmail.com\"   \n",
       "2         A1BM81XB4QHOA3                      Ahoro Blethends \"Seriously\"   \n",
       "3         A1MOSTXNIO5MPJ                                        Alan Krug   \n",
       "4         A2XQ5LZHTD4AFT                                         Alaturka   \n",
       "\n",
       "                                             summary  unixReviewTime  \n",
       "0                                         Wonderful!      1355616000  \n",
       "1                                       close to god      1071100800  \n",
       "2                    Must Read for Life Afficianados      1390003200  \n",
       "3  Timeless for every good and bad time in your l...      1317081600  \n",
       "4                                      A Modern Rumi      1033948800  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 2, 4, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.overall.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_sentiment(data):    \n",
    "    if data['overall'] > 3:\n",
    "        value = 1                 # 1 implies POSITIVE SENTIMENT\n",
    "    elif data['overall'] < 3:\n",
    "        value = -1                # -1 implies NEGATIVE SENTIMENT\n",
    "    else:\n",
    "        value = 0                 # 0 implies NEUTRAL SENTIMENT\n",
    "    return value\n",
    "\n",
    "data['sentiment'] = data.apply(assign_sentiment, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spiritually and mentally inspiring! A book tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is one my must have books. It is a master...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This book provides a reflection that you can a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I first read THE PROPHET in college back in th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A timeless classic.  It is a very demanding an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  sentiment\n",
       "0  Spiritually and mentally inspiring! A book tha...          1\n",
       "1  This is one my must have books. It is a master...          1\n",
       "2  This book provides a reflection that you can a...          1\n",
       "3  I first read THE PROPHET in college back in th...          1\n",
       "4  A timeless classic.  It is a very demanding an...          1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = data[['reviewText','sentiment']]\n",
    "review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/pallavi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "#######\n",
    "# based on http://www.cs.duke.edu/courses/spring14/compsci290/assignments/lab02.html\n",
    "stemmer = PorterStemmer()\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    # remove non letters\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    # tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # stem\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems\n",
    "######## \n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer = 'word',\n",
    "    tokenizer = tokenize,\n",
    "    lowercase = True,\n",
    "    stop_words = 'english',\n",
    "    max_features = 85\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 640.33 MiB, increment: 1.66 MiB\n",
      "peak memory: 649.57 MiB, increment: 129.46 MiB\n",
      "peak memory: 587.59 MiB, increment: 2.88 MiB\n",
      "peak memory: 458.90 MiB, increment: 0.05 MiB\n",
      "peak memory: 532.99 MiB, increment: 74.09 MiB\n",
      "Time: 489.6602680683136\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "%memit corpus_data_features = vectorizer.fit_transform(review.reviewText.tolist())\n",
    "%memit corpus_data_features_nd = corpus_data_features.toarray()\n",
    "corpus_data_features_nd.shape\n",
    "%memit X_train, X_test, y_train, y_test  = train_test_split(corpus_data_features_nd, review.sentiment, train_size=0.7, random_state=1)\n",
    "%memit log_model = LogisticRegression()\n",
    "%memit log_model = log_model.fit(X=X_train, y=y_train)\n",
    "t2 = time()\n",
    "print(\"Time:\",format(t2-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Usage Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 563.96 MiB, increment: 37.80 MiB\n",
      "0.7923\n",
      "Time: 0.41533803939819336\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "%memit y_pred = log_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "t2 = time()\n",
    "print(\"Time:\",format(t2-t1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
